{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Gs1TXV5OCOI"
   },
   "source": [
    "# SUBTASK 2 : Polarization Type Classification\n",
    "\n",
    "Overview : In this notbook the social media texts type or target polarization is classified as follows:\n",
    "1. Political/ideological polarization\n",
    "2. Racial or ethnic polarization\n",
    "3. Religious polarization\n",
    "4. Gender polarization\n",
    "5. Other\n",
    "\n",
    "### Experiment 1: Robust Baseline.\n",
    "- Establishes a stable training pipeline by fixing critical data issues (NaN handling, custom 80/20 splits)\n",
    "- implementing Focal Loss with Inverse-Frequency Class Weights to prevent the model from ignoring minority classes.\n",
    "\n",
    "### Experiment 2: Proposal-Aligned (\"Turbo\").\n",
    "Implements the core \"Learning by Contrast\" novelty.\n",
    "It utilizes Supervised Contrastive Learning (SCL) with a projection head for joint optimization (Loss = Focal + 0.5 * SCL)\n",
    "- Applies Dynamic Thresholding to automatically calculate the optimal probability cutoff for each specific class.\n",
    "\n",
    "### Experiment 3: Scale Comparison & Inference.\n",
    "Benchmarks XLM-R Base vs. Large (using gradient accumulation for memory efficiency) and includes a multilingual inference pipeline to visualize model confidence on real-world text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1muL3avQMtn"
   },
   "source": [
    "# 1. EXPERIMENTATION 1 - INITIAL CODE TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OXMnimn_uGEJ"
   },
   "source": [
    "## 1. Loading Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "n9FcOaDguGEJ"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FINAL SUBTASK 2 CODE: PROPOSAL-ALIGNED + VALID SPLIT FIX\n",
    "# ============================================================================\n",
    "\n",
    "# 1. INSTALL LIBRARIES\n",
    "!pip install transformers datasets scikit-learn pandas numpy torch accelerate -q\n",
    "\n",
    "# 2. IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaModel, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "import zipfile\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_dT3R2PDuGEK"
   },
   "source": [
    "## 2. Configuration and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "id": "S3LieC4vuGEK",
    "outputId": "b582edac-ca91-4b8d-d6e7-027f6a170cb8"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using device: cuda\n",
      "Please upload your ZIP file containing the 'train' and 'dev' folders:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-902ee920-e566-48b2-91d1-ccc2bb5c506a\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-902ee920-e566-48b2-91d1-ccc2bb5c506a\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving polar_data.zip to polar_data.zip\n",
      "Extracting polar_data.zip...\n",
      "\n",
      "Loading Training Data...\n",
      "Total labeled data loaded: 29987 rows\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 3. LOAD DATA (ONLY TRAIN FOLDER)\n",
    "from google.colab import files\n",
    "\n",
    "if os.path.exists(\"dataset_extracted\"):\n",
    "    print(\"Data folder found. Skipping upload.\")\n",
    "else:\n",
    "    print(\"Please upload your ZIP file containing the 'train' and 'dev' folders:\")\n",
    "    uploaded = files.upload()\n",
    "    if len(uploaded) > 0:\n",
    "        zip_filename = list(uploaded.keys())[0]\n",
    "        print(f\"Extracting {zip_filename}...\")\n",
    "        with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall(\"dataset_extracted\")\n",
    "    else:\n",
    "        raise ValueError(\"No file uploaded.\")\n",
    "\n",
    "def load_folder_csvs(folder_path):\n",
    "    all_files = glob.glob(os.path.join(folder_path, \"**/*.csv\"), recursive=True)\n",
    "    if not all_files: return pd.DataFrame()\n",
    "    df_list = []\n",
    "    for f in all_files:\n",
    "        try:\n",
    "            df = pd.read_csv(f)\n",
    "            df.columns = [c.lower() for c in df.columns]\n",
    "            df_list.append(df)\n",
    "        except: pass\n",
    "    return pd.concat(df_list, axis=0, ignore_index=True) if df_list else pd.DataFrame()\n",
    "\n",
    "print(\"\\nLoading Training Data...\")\n",
    "# We ONLY load the train folder because the dev folder has no labels\n",
    "train_dirs = glob.glob(\"dataset_extracted/**/train\", recursive=True)\n",
    "full_train_df = load_folder_csvs(train_dirs[0]) if train_dirs else load_folder_csvs(\"dataset_extracted\")\n",
    "\n",
    "print(f\"Total labeled data loaded: {len(full_train_df)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IxbDjKCkuGEK"
   },
   "source": [
    "## 3. Data Split, Cleaning and Weight Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dpx7cE7TuGEL",
    "outputId": "c7ff305f-8c52-4fbd-9126-1e3033cbe2a5"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Active Labels (5): ['political', 'racial/ethnic', 'religious', 'gender/sexual', 'other']\n",
      "Splitting data into 80% Train and 20% Validation...\n",
      "Final Train shape: (23989, 8)\n",
      "Final Dev shape:   (5998, 8)\n",
      "\n",
      "Calculating Class Weights...\n"
     ]
    }
   ],
   "source": [
    "# 4. PREPROCESS & SPLIT\n",
    "POTENTIAL_LABELS = [\n",
    "    'political', 'racial/ethnic', 'religious', 'gender/sexual', 'other',\n",
    "    'stereotype', 'vilification', 'dehumanization',\n",
    "    'extreme_language', 'lack_of_empathy', 'invalidation'\n",
    "]\n",
    "\n",
    "# Identify active labels\n",
    "TYPE_COLUMNS = [c for c in POTENTIAL_LABELS if c in full_train_df.columns]\n",
    "NUM_LABELS = len(TYPE_COLUMNS)\n",
    "print(f\"\\nActive Labels ({NUM_LABELS}): {TYPE_COLUMNS}\")\n",
    "\n",
    "# Fill NaNs with 0\n",
    "full_train_df[TYPE_COLUMNS] = full_train_df[TYPE_COLUMNS].fillna(0)\n",
    "\n",
    "# Clean Text\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text): return \"\"\n",
    "    return ' '.join([word for word in str(text).split() if not word.startswith('http')]).strip()\n",
    "\n",
    "full_train_df['text_clean'] = full_train_df['text'].apply(preprocess_text)\n",
    "\n",
    "# Filter for Polarization=1\n",
    "if 'polarization' in full_train_df.columns:\n",
    "    print(\"Filtering for polarization=1...\")\n",
    "    full_train_df = full_train_df[full_train_df['polarization'] == 1].reset_index(drop=True)\n",
    "\n",
    "# *** THE FIX: CREATE OUR OWN TRAIN/DEV SPLIT ***\n",
    "print(\"Splitting data into 80% Train and 20% Validation...\")\n",
    "train_df, dev_df = train_test_split(full_train_df, test_size=0.2, random_state=42)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "dev_df = dev_df.reset_index(drop=True)\n",
    "\n",
    "print(f\"Final Train shape: {train_df.shape}\")\n",
    "print(f\"Final Dev shape:   {dev_df.shape}\")\n",
    "\n",
    "# 5. CLASS WEIGHTS\n",
    "print(\"\\nCalculating Class Weights...\")\n",
    "train_labels = train_df[TYPE_COLUMNS].values.astype(np.float32)\n",
    "dev_labels = dev_df[TYPE_COLUMNS].values.astype(np.float32)\n",
    "\n",
    "pos_weights = []\n",
    "for i in range(NUM_LABELS):\n",
    "    pos_c = train_labels[:, i].sum()\n",
    "    neg_c = len(train_labels) - pos_c\n",
    "    weight = (neg_c / pos_c) if pos_c > 0 else 1.0\n",
    "    pos_weights.append(weight)\n",
    "\n",
    "pos_weights = torch.tensor(pos_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "# 6. LOSS FUNCTIONS\n",
    "class SupervisedContrastiveLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.07):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "    def forward(self, features, labels):\n",
    "        features = F.normalize(features, dim=1)\n",
    "        similarity_matrix = torch.matmul(features, features.T)\n",
    "        labels_dot = torch.matmul(labels, labels.T)\n",
    "        mask = (labels_dot > 0).float()\n",
    "        logits_mask = torch.scatter(torch.ones_like(mask), 1, torch.arange(mask.shape[0]).view(-1, 1).to(device), 0)\n",
    "        mask = mask * logits_mask\n",
    "        exp_logits = torch.exp(similarity_matrix / self.temperature) * logits_mask\n",
    "        log_prob = similarity_matrix / self.temperature - torch.log(exp_logits.sum(1, keepdim=True) + 1e-6)\n",
    "        sum_mask = mask.sum(1)\n",
    "        sum_mask[sum_mask == 0] = 1\n",
    "        return -(mask * log_prob).sum(1) / sum_mask\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, pos_weight, alpha=0.25, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.pos_weight = pos_weight\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    def forward(self, inputs, targets):\n",
    "        bce = F.binary_cross_entropy_with_logits(inputs, targets, pos_weight=self.pos_weight, reduction='none')\n",
    "        pt = torch.exp(-bce)\n",
    "        return (self.alpha * (1-pt)**self.gamma * bce).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHLl9yQHuGEL"
   },
   "source": [
    "## 4. Model Architecture and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 737,
     "referenced_widgets": [
      "46449f5fcfb24950ac3c066bd97747ec",
      "7296f553524a471ea636eb639f4f640d",
      "8a3d1ecda4d24921943bd24d1f89e653",
      "366f566cb23048d7844ae1bb9f4ca094",
      "a340d5970ae3431ca4ef1aa401be02d2",
      "b1d94403247949b4a8a9ee5322269c07",
      "fd741bfdd9184e158944d92f707fbbae",
      "ad2d2c012e984f67a78a0445368c60b7",
      "4c6a17f6bfeb4049a9042a395a4eec96",
      "1336e20ed5a04465a6fd72e68437f20f",
      "71b9ada62a95434f905de5fea0886a99",
      "f0ff91f1d8764d9b8415e26bffacf8a9",
      "2d9726d9d1db4effb7ad61f4680f6957",
      "507c731e8e934d06a43b0a1fd35c695a",
      "694b183f609e4870b19cea07657d1056",
      "935c10e820ff44e6979ea790dbc7ca72",
      "ce37029b65334df7a0748f60d673d97d",
      "0f46b949e3d246949fd74641d2a93a0f",
      "28f03d2a711e43deaecf96f7a6016b1e",
      "2079e2394cab496681d0941a0adcd949",
      "057fae70b97547ad8146ca2cabd220eb",
      "af77a02fcb1749fd9267757e1ef10ac6",
      "ee0ab03324524bfabb22d43b6b790b8b",
      "217a04a8c8254abea494db284124f936",
      "08498cdf9af749ff9037e26c449514ef",
      "6de77100441b4d878853d6f109b32e13",
      "22b401a5438248c98a28f2cea509b83e",
      "5c4912ab1aa043c7b7f16b6efba16c7a",
      "6a6d3ede15b04e7b80f5669ff194e222",
      "a044c508419348699bfb2603fb2dd48a",
      "0477850e42b449f982f416e1628843b6",
      "03136401fe134b22af0dc04c5392549c",
      "07066b376a4a4a768c211163b26f1d1f",
      "52235869797d44288a50faafd2389a61",
      "32a37488d5264f23a95ab994b8119ce9",
      "875f9dd7fff0430db13723a43f2fb07d",
      "db6648d16b934d6d8356b77d4151c9fb",
      "513e1b8d100f43ff8e5d5f8a12354e2e",
      "f8c49a39db9740e9acd6fd3f858f1460",
      "90d28eee11f9416eafbd82e3b1e238a5",
      "561b6ca45a784047b13b91facb5ce4e9",
      "d49b07d831d44e359da28e9e50a7069e",
      "5ff042b201e24df690c874ce37dd6195",
      "41e84d749f0a42808571de49aa8050bc",
      "b0f1c6617fac41ba8310fd78c5b2bd49",
      "934996f9591e411a870c1d631e94d74e",
      "73389d6b2ab344a685abbd97a6b69255",
      "20e5490c890442688c152e5e61a1f72c",
      "2c3f79d835e84c49b1f35c3931352734",
      "6e295bf1d17e4bb284672fa5a3b29b83",
      "6f2cd110d28a461f95dd6421de7f0d4d",
      "c60bd42868ff4436a5a96ebc98e7a18d",
      "76a296d7cee14a08bfda0e21fccc6476",
      "ad41fde5e02f4f738f3de6848fd34d1a",
      "c4708b193b5942dcbd2d549e3ccddc83",
      "a569b2352534412d8da2055a8cb58008",
      "c4d3a898dc034f94a97413259843fb12",
      "244ef15428c1423cb32140bb1dc42f30",
      "271bca01aa744461a5f5e43c5cfb27d6",
      "f4e4730d9e3f4001a8c0d370016c35e1",
      "7e2837adb2d148a6ba72fcd00f6b44f3",
      "323a762eff5646cca9ffba89ebc5ca33",
      "a73ccc0a5c524e3caa2da4dc6105999b",
      "1ec4a9bcb19b4236bf9bb24bb9edf41b",
      "664b44c86fba469f95215ed17a6faeb3",
      "2906743f45d042b68a7f7dec33863229",
      "13de2404986f403a815218abfc63708c",
      "43a1171ff08446feb2a6d448c2dc0339",
      "3925e3f3647f4ce8879b21551dd2cd62",
      "c0c42a65ad8741329d63825e6775ee5d",
      "064d3c41e4d04a709d20d16ace889428",
      "f5dbbe8e5be847aca04f6d64afe78ae6",
      "558586b149e7490984bc1520a57f2036",
      "5c1d1d0e1926403fb6c36936d4d4dabe",
      "1ff4b7a86c734e5d944a0621a7ab35b9",
      "8848aecef9ef464a800c5294423906da",
      "57cd6ca1c21d4ccebca3c03558669646",
      "5a837ce746ee4127aa63a6bcda85c579",
      "95d2845825674d6685fcc8e2e32c5bca",
      "a20cb9c3dad84ccaac6b58c9c84dfc11",
      "bb861e4a491141d7a1cb8aa2d1860e3e",
      "d3299db3f849480fa7e487cb60a61c6c",
      "a81361f6cf1b4ea18b6df6d8076115cb",
      "2ae29ea0b91d41eb94b90e70c8f3d58f",
      "a581a7f664e64eb6a74d70688a5413b6",
      "c8918161331d44f5b5823b3ea4f2d58c",
      "f1ec493233a149a59c901737517f5ed5",
      "97054215ac944f13a3250b1b237f5eac",
      "9713125aef4041bc805c46c9ee996dda",
      "975bcedacc014647b30ebc394e1619ee",
      "52aa846c92794cc3820cf6928dc66774",
      "75ac19b5629a42cfa87a7c952020cf88",
      "c6e813b084584a81931ed88ddd505505",
      "bb92bee15ff648a4b369df5f0f58f34a",
      "36a47f3271f6416aaf55e8e6be7da69a",
      "0aff301b9a2140c1b7764422f2a1c0e0",
      "9c648da9632e4eeca1a1475762f748d7",
      "f596bb5ff85147febfe1bd9b9f9c3ecb",
      "cbeb6a69264a4a5d912dbfab029df89e",
      "293c20d0e9d7468c9c92c55426bbf038",
      "478e6285042c4664b0153de659d4cfba",
      "96e25a2e72d54f3f893180d89283d2ae",
      "22f5b74cd547488d95f8472f0e0d91ba",
      "251f84b307a645bb8edbd3f96c183b01",
      "47666a8d041d4a819ae2a37fcbbd59cb",
      "7ce55442481a420699fc8f17f39ddf8a",
      "3f2d5e8bc3914d2c90bb36ff4ba07307",
      "20a3bbed4d3d4ed7b11575a89a46ba68",
      "3051725760b84a949cbdbcb079ae3deb",
      "d25f38e77fa94f38bae7c36a22463709",
      "16571c07ec9d44f48ffc934f3eeb58d4",
      "558b534cfe804295b3652b9a783a8bea",
      "95d6a9a8fdbf4403a72536614c2e270c",
      "ffff919ee1d04145b5e26a8421f89e16",
      "e924c2881e4146de8daf007348798e6e",
      "b3612321a71b42ffb3a5c1e8c7f5756e",
      "277db2723d574db8a23f4d912e271d1e",
      "a8bce92a9ae94f60bb0290c5f29d0861",
      "4db1d13bd6ca49bcb37391877fcdc43b",
      "fafe323c5191458d91a94996fab42a83",
      "7733e70068004d6bab9eff3a93e40f45",
      "b2bca8131a1d49e2ac74a44cb0b92718",
      "da60b5fec0674d809130b81abd21bb04",
      "011e926efbaf4d67948b1365db9c7118",
      "17a9f6ebdb194864a7d3bec0257c0111",
      "0cfca90c1c3f4c588ff0c282f2e06450",
      "d1c0041ed5314f6ea1a516ab773e4379",
      "5b1a1d1de0be474bbb06c7d02904f48f",
      "8ce2c7f2786747a0aa254c0430ecdbe6",
      "cee06e4cefa0460f97fc257a7322b0c0",
      "3a1bbaad3faf444f8ec97512cd539930",
      "57f26370ddb949c1ad4d6d5e18619d00",
      "b6b87200406e4253afefa610f8c3e66f",
      "f53338a9a3cc4cc8ad9b5d392cafd0d7",
      "756c9301e73c4950b87ee1ef8941565b",
      "c9cf316fbff44fd6b4b99e17697dcd3e",
      "f54f196f803049d7aa885ec4b726f20a",
      "b34c016c85ab4ab7908d55048f2b1154",
      "206c9ba427b8494eada1cb210c4146f6",
      "f8e13730e4fd4b33aadbc8f182ad2e92",
      "a3cddedbdcf14c6d90aec4e5a6c19e5b",
      "fff66ba0f1934723a7e6720045f19a01",
      "cb306a2604fd4124abb858a9e711154a"
     ]
    },
    "id": "xFS94hsxHQK5",
    "outputId": "b072ce77-b283-44be-84ff-306629e772f1"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "46449f5fcfb24950ac3c066bd97747ec"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f0ff91f1d8764d9b8415e26bffacf8a9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ee0ab03324524bfabb22d43b6b790b8b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "52235869797d44288a50faafd2389a61"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b0f1c6617fac41ba8310fd78c5b2bd49"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Starting Training...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch 1:   0%|          | 0/1500 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a569b2352534412d8da2055a8cb58008"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1 Loss: 0.7004 | Dev Macro F1: 0.4733\n",
      "\u2713 Saved Best Model\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch 2:   0%|          | 0/1500 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "13de2404986f403a815218abfc63708c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 2 Loss: 0.6211 | Dev Macro F1: 0.5283\n",
      "\u2713 Saved Best Model\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch 3:   0%|          | 0/1500 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5a837ce746ee4127aa63a6bcda85c579"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 3 Loss: 0.5938 | Dev Macro F1: 0.5112\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch 4:   0%|          | 0/1500 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9713125aef4041bc805c46c9ee996dda"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 4 Loss: 0.5680 | Dev Macro F1: 0.5214\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch 5:   0%|          | 0/1500 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "293c20d0e9d7468c9c92c55426bbf038"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 5 Loss: 0.5421 | Dev Macro F1: 0.5864\n",
      "\u2713 Saved Best Model\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch 6:   0%|          | 0/1500 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "16571c07ec9d44f48ffc934f3eeb58d4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 6 Loss: 0.5200 | Dev Macro F1: 0.5672\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch 7:   0%|          | 0/1500 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b2bca8131a1d49e2ac74a44cb0b92718"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 7 Loss: 0.5035 | Dev Macro F1: 0.5897\n",
      "\u2713 Saved Best Model\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch 8:   0%|          | 0/1500 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b6b87200406e4253afefa610f8c3e66f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 8 Loss: 0.4873 | Dev Macro F1: 0.5939\n",
      "\u2713 Saved Best Model\n",
      "\n",
      "Final Best Macro F1: 0.5939\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 7. MODEL\n",
    "class ContrastiveXLMR(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super().__init__()\n",
    "        self.roberta = XLMRobertaModel.from_pretrained('xlm-roberta-base')\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.projection = nn.Sequential(nn.Linear(768, 768), nn.ReLU(), nn.Linear(768, 128))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(768, 1536), nn.LayerNorm(1536), nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(1536, num_labels)\n",
    "        )\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        out = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled = out.last_hidden_state[:, 0, :]\n",
    "        return self.classifier(self.dropout(pooled)), self.projection(pooled)\n",
    "\n",
    "# 8. TRAINING\n",
    "class PolarDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.texts = texts; self.labels = labels; self.tokenizer = tokenizer\n",
    "    def __len__(self): return len(self.texts)\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tokenizer(str(self.texts[idx]), padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n",
    "        return {'input_ids': enc['input_ids'][0], 'attention_mask': enc['attention_mask'][0], 'labels': torch.tensor(self.labels[idx])}\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 8\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
    "train_loader = DataLoader(PolarDataset(train_df['text_clean'].values, train_labels, tokenizer), batch_size=BATCH_SIZE, shuffle=True)\n",
    "dev_loader = DataLoader(PolarDataset(dev_df['text_clean'].values, dev_labels, tokenizer), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model = ContrastiveXLMR(NUM_LABELS).to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "criterion_cls = FocalLoss(pos_weights)\n",
    "criterion_scl = SupervisedContrastiveLoss(temperature=0.1)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, 0, len(train_loader)*EPOCHS)\n",
    "\n",
    "print(\"\\nStarting Training...\")\n",
    "best_f1 = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        ids, mask, lbls = batch['input_ids'].to(device), batch['attention_mask'].to(device), batch['labels'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits, feats = model(ids, mask)\n",
    "        loss = criterion_cls(logits, lbls) + (0.5 * criterion_scl(feats, lbls).mean())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        loss_sum += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    all_preds, all_lbls = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in dev_loader:\n",
    "            ids, mask = batch['input_ids'].to(device), batch['attention_mask'].to(device)\n",
    "            logits, _ = model(ids, mask)\n",
    "            all_preds.append((torch.sigmoid(logits) > 0.4).float().cpu().numpy())\n",
    "            all_lbls.append(batch['labels'].cpu().numpy())\n",
    "\n",
    "    if len(all_preds) > 0:\n",
    "        macro_f1 = f1_score(np.vstack(all_lbls), np.vstack(all_preds), average='macro', zero_division=0)\n",
    "        print(f\"Epoch {epoch+1} Loss: {loss_sum/len(train_loader):.4f} | Dev Macro F1: {macro_f1:.4f}\")\n",
    "        if macro_f1 > best_f1:\n",
    "            best_f1 = macro_f1\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n",
    "            print(\"\u2713 Saved Best Model\")\n",
    "\n",
    "print(f\"\\nFinal Best Macro F1: {best_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fqf71mIKP-Dq"
   },
   "source": [
    "# 2. EXPERIMENTATION 2: CODE WITH EXTENDED TRAINGING EPOCHS, GRADIENT ACCUMULATION AND DYNAMIC THRESHOLDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jl7kP-7KuGEM"
   },
   "source": [
    "## 1. Model and Optimal Threshold Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "N8STRRTquGEM"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ENHANCED TRAINING: Gradient Accumulation + Dynamic Thresholds\n",
    "# ============================================================================\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "# 1. CONFIGURATION (UPDATED)\n",
    "# ============================================================================\n",
    "BATCH_SIZE = 16\n",
    "GRAD_ACCUM_STEPS = 2  # Effective Batch Size = 32 (Better for Contrastive Loss)\n",
    "EPOCHS = 12           # Increased from 8 to 12\n",
    "LR = 2e-5\n",
    "\n",
    "# 2. MODEL & OPTIMIZER SETUP\n",
    "# ============================================================================\n",
    "model = ContrastiveXLMR(NUM_LABELS).to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=LR, weight_decay=0.01)\n",
    "\n",
    "# Switch to Cosine Scheduler (Better for longer training)\n",
    "total_steps = len(train_loader) * EPOCHS // GRAD_ACCUM_STEPS\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=int(0.1*total_steps), num_training_steps=total_steps)\n",
    "\n",
    "# Loss Functions\n",
    "criterion_cls = FocalLoss(pos_weights)\n",
    "criterion_scl = SupervisedContrastiveLoss(temperature=0.1)\n",
    "\n",
    "# 3. HELPER: FIND OPTIMAL THRESHOLDS\n",
    "# ============================================================================\n",
    "def optimize_thresholds(y_true, y_probs):\n",
    "    \"\"\"Finds the best F1 threshold for each class independently.\"\"\"\n",
    "    best_thresholds = []\n",
    "    best_f1s = []\n",
    "\n",
    "    # Iterate over each class column\n",
    "    for i in range(y_true.shape[1]):\n",
    "        best_t = 0.5\n",
    "        best_f1 = 0.0\n",
    "\n",
    "        # Check thresholds from 0.20 to 0.80\n",
    "        for t in np.arange(0.2, 0.8, 0.05):\n",
    "            preds = (y_probs[:, i] > t).astype(int)\n",
    "            score = f1_score(y_true[:, i], preds, zero_division=0)\n",
    "            if score > best_f1:\n",
    "                best_f1 = score\n",
    "                best_t = t\n",
    "\n",
    "        best_thresholds.append(best_t)\n",
    "        best_f1s.append(best_f1)\n",
    "\n",
    "    return best_thresholds, best_f1s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ikgDKPpauGEM"
   },
   "source": [
    "## 2. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437,
     "referenced_widgets": [
      "a35d5e10d5f44a18b95c2ca5b9b05bea",
      "be0225517a3840208516243c5e899ca8",
      "4793e22cb5c84c1d80676fcd149e5205",
      "e4b9f5a415e94ad3a51ebcb966f9ec51",
      "aab9b9f1421c42df8bc5786cdd30a3ca",
      "3c370324c8ff49faa792a54e70f9a841",
      "e81f7f7d7e8f402595f1003c73581d50",
      "1c511565347b4122b6940859259cb88b",
      "f8dd094030fa449cbaa950a6f54a7ef5",
      "b75c7b09d7084623b499f0d4639a4a8f",
      "9fa4beb3c30441e79c9760e27250c762",
      "7bafa43573444736999627ba440e81aa",
      "b4a221b7ee5b4f29a7a880a55851698e",
      "693c549ebd044f3ab0e155f9d02aabc0",
      "a0be394e1955454cb05e5353360508b2",
      "169052a753c44d419414325f237dcd0e",
      "c5b139e3acb648858bc7f370bb1cf066",
      "c35cdff9501b4914920d60823932be55",
      "411bbb6f2b664db3a98d9f37d01038af",
      "d8f29848199d41f7b068030cd823f2cb",
      "a415048d8b1246f28f2c99b2dfb7c2e5",
      "5e786375d09347828a2ba9bf3f4387bf",
      "4b90bad906f348828b465e16f0ddbc9f",
      "195f7ea067004c74bf2736de8464c064",
      "5fbf294ab4fd431cb3ba182e0e7e0dad",
      "d638e9bc7bad4c24b934f72f6e2c86a8",
      "0628421a1e5947d8be1b6993c7aa73a2",
      "97761b3c77b64b9d9177c4d9a17cfb84",
      "59d9a81e40814c1a8cbdd6fbbd7efa96",
      "7820cdd54c2b485ba3802a64270191ce",
      "2633f9a1368546268a76c1d2beb27c87",
      "9576289a993041f7945a2ab72b02b567",
      "a683187122ac4875addf3d1ade07fca4",
      "943e09e1fef44cb4840c11b1251a5753",
      "4cb59c38dc67478597c0b06f5c13ce7b",
      "46ceb01129b1440fb83eeafc9d50ed9d",
      "73dee428664f4ba193391f8e19b88a32",
      "d30fccbca2e84d1dac24ae03f7f75f29",
      "a6013b500bb84c22bb28ffc1d0bbeaa6",
      "74028d2163d8420b840dba7764cae2c6",
      "5a9382e1b2a9493ea3d8807a60e3fc1a",
      "7aadc5f50e2e43a09f92f311b82f84e1",
      "98b724cea90d4c44911fc53b3eb5110a",
      "c56349beed7843eab0dc1047eb69c369",
      "eaaeb108daa9413690fae3e1db033198",
      "f4925ad99e9948ae8ab92f955fe22612",
      "708b266bf58740d987f727021902af82",
      "403770f10fd24ee79beb1ccff52ef28f",
      "73ce877077ea476ba9d3c941db3a2922",
      "7c8fb99ddd5f432e91cb7a1aa12d7565",
      "f3936fed7a2d43cab5c8993589bfe657",
      "bda84598c945416185d9fb5e9f57bc9c",
      "cfd4185b6ae54d4f946ec7f4ea70c9b1",
      "9d51e8fca89046c8bdc6abe83a9ffc1b",
      "629aca28425348c7be277f0750869eb6",
      "aeeb1ffef37d44fd9f74cc7608988753",
      "aee41449c65c43ecbcb9e007d3dd66f7",
      "318bb313b02c4f67af8ba2e669bce7ee",
      "f7edef9d151b4978a2d3da364bad9ffb",
      "f6cf938f30e6440497fcab0d4b8f3c77",
      "293efe6ac43c493988a125b35c2afa29",
      "506aa93b8bfd42119bedfcffcc034e9d",
      "9fd9debe71af46b7b6779d9dceca91c6",
      "5c665b1ef04847f5b5e1ae7851ae3873",
      "f4c5ea8116404f17b8bcefe121dff755",
      "250358a5514f4ab48df80dd0a710a5c1",
      "f1cd865e518b4ebc83f2473f0701812e",
      "eff8fee176e14b878809c53f9e6c9c0e",
      "75af974e38c34b16ba45354fae960390",
      "5df2177be392485bb9216054f08f2e1b",
      "b0858f0033a241ddbe258fd00a280d0c",
      "3b86dd7e01e447a98594cc3bfadc6117",
      "9ecc0ed6a1a34f80af6a66bc4c80b914",
      "891a81ec6b4042ad9043e6ec978ac4b4",
      "62023764663845e2b6b47e5f594fdddd",
      "9ac62732c8a1408ebe82397a4e236d89",
      "6171f33506874521985250b61d68939e",
      "5198f3eee2374ad689ade0ad900c6d32",
      "fd2ce1333db04d5689635103a6549a27",
      "a3b6a73c01444abdbf74d378c0cfe3a2",
      "6835471389924cfcb6a2b7ac96496528",
      "4aab6c9c4dbe437aafd9ae7d7a6995f7",
      "4bf76617f96c4221a8884c63c9bb630f",
      "f62fbbad6bd44e4ba8217fd5d3237b27",
      "45d247af39da41fe8387b07d1c49b5c3",
      "4968b9c3e7344018bedbd295917ceb6a",
      "51655e421277402b83048729934b1d33",
      "e4e0475d0df04dc99ba06c865857c09e",
      "0d592f367c444a7ab67222d977288ac0",
      "7eae913313bb418b915456dc8f880e81",
      "bd4aeb22625f40bd83fd035443bcdb9d",
      "24fb489414e24f27929b227c4ea08fd6",
      "ae636f158911499e9e6d065a78f5c067",
      "a8c1dcd0ed5a4d0caffe62b20dd21006",
      "c768ec33ec8747a8a81f28c6d2f61010",
      "85e3abe8aaea49e293fa9bc2dd4712ba",
      "4fb04f7f89314ad999fef6bb4a25dc00",
      "425d1c63742144e98fdc8449d5414b8c",
      "ac83449c853f41bf8a869a1b4745aaa2",
      "99b74c6d92a54a8dad9228de79c20ffb",
      "84a03ec03e534a96b1a01381c99402ad",
      "deb3d596b3364335962e79e96026977f",
      "338baa420307487db1e4f49521a410aa",
      "090c59f325384989832a03ad77c12df1",
      "97b80d6730f14b4c984047ab8cdb12c5",
      "0b08dccae43449c08a8e9e43aaf82a97",
      "5345431c82bb4a48a18c26586b8047f7",
      "dd801e5ad0884e71b1077869d4ef28df",
      "fcf443faea1d40ad92067851249eba04",
      "c2d2f5feea154820853fa49684379023",
      "6b5b04946d9d4330b235ed06eab57493",
      "63735defeab24092b36ce216a074a1c2",
      "255b3cefdb334267991b30e03fedd3dd",
      "7ad85cca29274d74ae88402d601d5512",
      "ce8f9a38b4d24f9194d3f2b7567e78a7",
      "fc465866e1dd4b03ac7308b1c65593f5",
      "8fe4ba281ff342c38ed0bef67c82ae16",
      "5407c7621e764ec8a618868d37f874b7",
      "ff10822b8b0a41dda72e07c91aa854b6",
      "0afcf0e5211347b1a545c56ef7d7a517",
      "7a963646089b47588f6b5f73bc0a289d",
      "81fca2add4604ff1ad623af2b0ba47f0",
      "0c220a1671564f07b50fd8b267e42248",
      "359a3f50ed8e4f219c46206eab127273",
      "92abc16bbe1a4e3ab07e92a5b7ef04ba",
      "bfd6f9c0e14448f1b9ee7790e8ae14b6",
      "38d73172db2b493eabab6f0411a08c57",
      "079feac5f31a495dbab0c17ad711c70e",
      "2ffedb0302e446bb8001206867236049",
      "a84eb2921f7f4967bfedd2c4d021683b",
      "9012915438fb4bd8b1732570228d672d",
      "8733eebff70f4fb3a8508ebc63cea419"
     ]
    },
    "id": "eXPyeg_guGEM",
    "outputId": "9b291328-4b9e-4177-fe5d-fb71f4ed59a4"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Starting Enhanced Training (Epochs: 12, Eff. Batch: 32)...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch 1:   0%|          | 0/1500 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a35d5e10d5f44a18b95c2ca5b9b05bea"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch 2:   0%|          | 0/1500 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7bafa43573444736999627ba440e81aa"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch 3:   0%|          | 0/1500 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4b90bad906f348828b465e16f0ddbc9f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch 4:   0%|          | 0/1500 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "943e09e1fef44cb4840c11b1251a5753"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch 5:   0%|          | 0/1500 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eaaeb108daa9413690fae3e1db033198"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch 6:   0%|          | 0/1500 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aeeb1ffef37d44fd9f74cc7608988753"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch 7:   0%|          | 0/1500 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f1cd865e518b4ebc83f2473f0701812e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch 8:   0%|          | 0/1500 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5198f3eee2374ad689ade0ad900c6d32"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch 9:   0%|          | 0/1500 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d592f367c444a7ab67222d977288ac0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch 10:   0%|          | 0/1500 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "99b74c6d92a54a8dad9228de79c20ffb"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch 11:   0%|          | 0/1500 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6b5b04946d9d4330b235ed06eab57493"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch 12:   0%|          | 0/1500 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "81fca2add4604ff1ad623af2b0ba47f0"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "# 4. TRAINING LOOP\n",
    "# ============================================================================\n",
    "print(f\"\\nStarting Enhanced Training (Epochs: {EPOCHS}, Eff. Batch: {BATCH_SIZE*GRAD_ACCUM_STEPS})...\")\n",
    "best_macro_f1 = 0\n",
    "best_thresholds = [0.5] * NUM_LABELS # Default\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # --- TRAINING PHASE ---\n",
    "    for step, batch in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}\")):\n",
    "        ids = batch['input_ids'].to(device)\n",
    "        mask = batch['attention_mask'].to(device)\n",
    "        lbls = batch['labels'].to(device)\n",
    "\n",
    "        # Forward\n",
    "        logits, feats = model(ids, mask)\n",
    "\n",
    "        # Combined Loss\n",
    "        loss = criterion_cls(logits, lbls) + (0.5 * criterion_scl(feats, lbls).mean())\n",
    "\n",
    "        # Normalize loss for accumulation\n",
    "        loss = loss / GRAD_ACCUM_STEPS\n",
    "        loss.backward()\n",
    "\n",
    "        # Step only after accumulation\n",
    "        if (step + 1) % GRAD_ACCUM_STEPS == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        loss_sum += loss.item() * GRAD_ACCUM_STEPS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgMQD_wnuGEN"
   },
   "source": [
    "## 3. Evaluation Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ld_jtEDRJV1t",
    "outputId": "e60b6a5e-c10c-4736-8a8b-4976ba7d0e60"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 12 | Loss: 0.4150 | Dev Macro F1: 0.6164 \u2b50\n",
      "   -> Opt Thresholds: ['0.50', '0.60', '0.70', '0.75', '0.55']\n",
      "   \u2713 Saved New Best Model\n",
      "\n",
      "Final Best Macro F1: 0.6164\n",
      "Optimal Thresholds found: [np.float64(0.49999999999999994), np.float64(0.5999999999999999), np.float64(0.7), np.float64(0.7499999999999998), np.float64(0.5499999999999999)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "    # --- EVALUATION PHASE ---\n",
    "    model.eval()\n",
    "    all_probs, all_lbls = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dev_loader:\n",
    "            ids = batch['input_ids'].to(device)\n",
    "            mask = batch['attention_mask'].to(device)\n",
    "\n",
    "            logits, _ = model(ids, mask)\n",
    "            # Store probabilities (0.0 to 1.0), NOT hard predictions yet\n",
    "            probs = torch.sigmoid(logits)\n",
    "\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "            all_lbls.append(batch['labels'].cpu().numpy())\n",
    "\n",
    "    if len(all_probs) > 0:\n",
    "        y_probs = np.vstack(all_probs)\n",
    "        y_true = np.vstack(all_lbls)\n",
    "\n",
    "        # DYNAMIC THRESHOLDING: Calculate best threshold for THIS epoch\n",
    "        current_thresholds, class_f1s = optimize_thresholds(y_true, y_probs)\n",
    "\n",
    "        # Apply optimal thresholds to get predictions\n",
    "        y_pred = np.zeros_like(y_probs)\n",
    "        for i, t in enumerate(current_thresholds):\n",
    "            y_pred[:, i] = (y_probs[:, i] > t).astype(int)\n",
    "\n",
    "        macro_f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "        avg_loss = loss_sum / len(train_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1} | Loss: {avg_loss:.4f} | Dev Macro F1: {macro_f1:.4f} \u2b50\")\n",
    "        print(f\"   -> Opt Thresholds: {['{:.2f}'.format(t) for t in current_thresholds]}\")\n",
    "\n",
    "        # Save Best\n",
    "        if macro_f1 > best_macro_f1:\n",
    "            best_macro_f1 = macro_f1\n",
    "            best_thresholds = current_thresholds\n",
    "            torch.save(model.state_dict(), 'best_model_turbo.pt')\n",
    "            print(\"   \u2713 Saved New Best Model\")\n",
    "    else:\n",
    "        print(\"Warning: Dev set evaluation failed.\")\n",
    "\n",
    "print(f\"\\nFinal Best Macro F1: {best_macro_f1:.4f}\")\n",
    "print(\"Optimal Thresholds found:\", best_thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BOOTSTRAPPING CODE"
   ],
   "metadata": {
    "id": "yKxl1jTzuIWu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def run_bootstrap_on_test(all_probs_list, all_lbls_list, thresholds, n_iterations=1000):\n",
    "    print(f\"Starting Bootstrapping on Test Data (n={n_iterations})...\")\n",
    "\n",
    "    # 1. Ensure data is in numpy format\n",
    "    if isinstance(all_probs_list, list):\n",
    "        y_probs = np.vstack(all_probs_list)\n",
    "        y_true = np.vstack(all_lbls_list)\n",
    "    else:\n",
    "        y_probs = all_probs_list\n",
    "        y_true = all_lbls_list\n",
    "\n",
    "    # 2. Convert Probabilities to Binary Predictions using your Best Thresholds\n",
    "    # We do this ONCE before resampling to save time\n",
    "    print(f\"Applying thresholds: {['{:.2f}'.format(t) for t in thresholds]}\")\n",
    "    y_pred_binary = np.zeros_like(y_probs)\n",
    "    for i, t in enumerate(thresholds):\n",
    "        y_pred_binary[:, i] = (y_probs[:, i] > t).astype(int)\n",
    "\n",
    "    boot_scores = []\n",
    "    n_samples = len(y_true)\n",
    "    # Create an array of indices [0, 1, 2, ... N-1] to resample\n",
    "    indices = np.arange(n_samples)\n",
    "\n",
    "    # 3. Bootstrap Loop\n",
    "    for i in range(n_iterations):\n",
    "        # Resample indices with replacement\n",
    "        # This creates a \"virtual\" test set of the same size\n",
    "        sample_indices = resample(indices, replace=True)\n",
    "\n",
    "        y_true_sample = y_true[sample_indices]\n",
    "        y_pred_sample = y_pred_binary[sample_indices]\n",
    "\n",
    "        # Calculate Macro F1 for this iteration\n",
    "        score = f1_score(y_true_sample, y_pred_sample,\n",
    "                         average='macro', zero_division=0)\n",
    "        boot_scores.append(score)\n",
    "\n",
    "    # 4. Calculate Confidence Intervals (95%)\n",
    "    alpha = 0.95\n",
    "    p_lower = ((1.0 - alpha) / 2.0) * 100  # 2.5th percentile\n",
    "    p_upper = (alpha + ((1.0 - alpha) / 2.0)) * 100 # 97.5th percentile\n",
    "\n",
    "    mean_score = np.mean(boot_scores)\n",
    "    lower_bound = np.percentile(boot_scores, p_lower)\n",
    "    upper_bound = np.percentile(boot_scores, p_upper)\n",
    "\n",
    "    # 5. Output Results\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\"FINAL BOOTSTRAP RESULTS (Macro F1)\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"Original Score: {0.6164}\") # Your specific run\n",
    "    print(f\"Bootstrap Mean: {mean_score:.4f}\")\n",
    "    print(f\"95% CI:         [{lower_bound:.4f} - {upper_bound:.4f}]\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "    print(\"\\nLaTeX Table Format:\")\n",
    "    print(f\"{mean_score:.3f} ({lower_bound:.3f}--{upper_bound:.3f})\")\n",
    "\n",
    "# --- EXECUTE ---\n",
    "# This uses the variables currently in your memory\n",
    "run_bootstrap_on_test(all_probs, all_lbls, best_thresholds)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G5oYwd2CuM-0",
    "outputId": "eb825795-f05a-4fd4-f384-81a479175115"
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Starting Bootstrapping on Test Data (n=1000)...\n",
      "Applying thresholds: ['0.50', '0.60', '0.70', '0.75', '0.55']\n",
      "\n",
      "========================================\n",
      "FINAL BOOTSTRAP RESULTS (Macro F1)\n",
      "========================================\n",
      "Original Score: 0.6164\n",
      "Bootstrap Mean: 0.6162\n",
      "95% CI:         [0.5996 - 0.6310]\n",
      "========================================\n",
      "\n",
      "LaTeX Table Format:\n",
      "0.616 (0.600--0.631)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P96Ce-mPv97F"
   },
   "source": [
    "# 3. MULTILINGUAL INFERENCE DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "10PGawsXQHrz",
    "outputId": "e65a47b2-1a1f-4d8e-ba76-534052e3ba23"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RUNNING MULTILINGUAL PREDICTIONS...\n",
      "\n",
      "Input: \"The radical left is destroying our country and ruining our traditional values.\"\n",
      "Label                | Conf     | Prediction\n",
      "---------------------------------------------\n",
      "Political            | 0.9326   | \u2705 YES\n",
      "\n",
      "==================================================\n",
      "\n",
      "Input: \"Las feministas odian a los hombres y quieren destruir la familia tradicional.\"\n",
      "Label                | Conf     | Prediction\n",
      "---------------------------------------------\n",
      "Political            | 0.8778   | \u2705 YES\n",
      "Religious            | 0.4233   | \u2705 YES\n",
      "Gender/Sexual        | 0.9864   | \u2705 YES\n",
      "\n",
      "==================================================\n",
      "\n",
      "Input: \"Ces immigrants refusent de s'adapter \u00e0 notre culture et volent nos emplois.\"\n",
      "Label                | Conf     | Prediction\n",
      "---------------------------------------------\n",
      "Racial/Ethnic        | 0.9727   | \u2705 YES\n",
      "\n",
      "==================================================\n",
      "\n",
      "Input: \"\u0939\u092e\u093e\u0930\u093e \u0927\u0930\u094d\u092e \u0916\u0924\u0930\u0947 \u092e\u0947\u0902 \u0939\u0948, \u0939\u092e\u0947\u0902 \u0909\u0928\u0938\u0947 \u0932\u0921\u093c\u0928\u093e \u0939\u094b\u0917\u093e \u0914\u0930 \u0909\u0928\u094d\u0939\u0947\u0902 \u092c\u093e\u0939\u0930 \u0928\u093f\u0915\u093e\u0932\u0928\u093e \u0939\u094b\u0917\u093e\u0964\"\n",
      "Label                | Conf     | Prediction\n",
      "---------------------------------------------\n",
      "Political            | 0.8660   | \u2705 YES\n",
      "Racial/Ethnic        | 0.8202   | \u2705 YES\n",
      "Religious            | 0.9812   | \u2705 YES\n",
      "\n",
      "==================================================\n",
      "\n",
      "Input: \"\u12ed\u1205 \u1261\u12f5\u1295 \u12e8\u1205\u12dd\u1265 \u1320\u120b\u1275 \u1290\u12cd \u12a5\u1293\u121d \u1218\u12c8\u1308\u12f5 \u12a0\u1208\u1260\u1275\u1362\"\n",
      "Label                | Conf     | Prediction\n",
      "---------------------------------------------\n",
      "Political            | 0.9207   | \u2705 YES\n",
      "Other                | 0.6359   | \u2705 YES\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# MULTILINGUAL INFERENCE DEMO\n",
    "# ============================================================================\n",
    "\n",
    "def predict_polarization(text, model, tokenizer, threshold=0.4):\n",
    "    model.eval()\n",
    "    # 1. Clean & Tokenize\n",
    "    clean_text = ' '.join([word for word in text.split() if not word.startswith('http')]).strip()\n",
    "    encoded = tokenizer(clean_text, return_tensors='pt', padding='max_length', truncation=True, max_length=128)\n",
    "\n",
    "    input_ids = encoded['input_ids'].to(device)\n",
    "    attention_mask = encoded['attention_mask'].to(device)\n",
    "\n",
    "    # 2. Predict\n",
    "    with torch.no_grad():\n",
    "        logits, _ = model(input_ids, attention_mask)\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()[0]\n",
    "\n",
    "    # 3. Pretty Print\n",
    "    print(f\"Input: \\\"{text}\\\"\")\n",
    "    print(f\"{'Label':<20} | {'Conf':<8} | {'Prediction'}\")\n",
    "    print(\"-\" * 45)\n",
    "\n",
    "    active_labels = []\n",
    "    for idx, label in enumerate(TYPE_COLUMNS):\n",
    "        score = probs[idx]\n",
    "        if score > threshold:\n",
    "            print(f\"{label.title():<20} | {score:.4f}   | \u2705 YES\")\n",
    "            active_labels.append(label)\n",
    "        else:\n",
    "            # Uncomment below if you want to see all probabilities\n",
    "            # print(f\"{label.title():<20} | {score:.4f}   | \u274c\")\n",
    "            pass\n",
    "\n",
    "    if not active_labels:\n",
    "        print(\">> No polarization detected (or low confidence)\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# ==========================================\n",
    "# TEST CASES (Multilingual)\n",
    "# ==========================================\n",
    "examples = [\n",
    "    # 1. English (Political)\n",
    "    \"The radical left is destroying our country and ruining our traditional values.\",\n",
    "\n",
    "    # 2. Spanish (Gender/Sexual) -> \"Feminists hate men and want to destroy the family.\"\n",
    "    \"Las feministas odian a los hombres y quieren destruir la familia tradicional.\",\n",
    "\n",
    "    # 3. French (Racial/Ethnic) -> \"These immigrants refuse to adapt to our culture.\"\n",
    "    \"Ces immigrants refusent de s'adapter \u00e0 notre culture et volent nos emplois.\",\n",
    "\n",
    "    # 4. Hindi (Religious) -> \"Our religion is in danger, we must fight them.\"\n",
    "    \"\u0939\u092e\u093e\u0930\u093e \u0927\u0930\u094d\u092e \u0916\u0924\u0930\u0947 \u092e\u0947\u0902 \u0939\u0948, \u0939\u092e\u0947\u0902 \u0909\u0928\u0938\u0947 \u0932\u0921\u093c\u0928\u093e \u0939\u094b\u0917\u093e \u0914\u0930 \u0909\u0928\u094d\u0939\u0947\u0902 \u092c\u093e\u0939\u0930 \u0928\u093f\u0915\u093e\u0932\u0928\u093e \u0939\u094b\u0917\u093e\u0964\",\n",
    "\n",
    "    # 5. Amharic (Political/Ethnic - common in your dataset)\n",
    "    # \"This group is an enemy of the people.\"\n",
    "    \"\u12ed\u1205 \u1261\u12f5\u1295 \u12e8\u1205\u12dd\u1265 \u1320\u120b\u1275 \u1290\u12cd \u12a5\u1293\u121d \u1218\u12c8\u1308\u12f5 \u12a0\u1208\u1260\u1275\u1362\"\n",
    "]\n",
    "\n",
    "print(\"RUNNING MULTILINGUAL PREDICTIONS...\\n\")\n",
    "for text in examples:\n",
    "    predict_polarization(text, model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4adVHYzaNC4"
   },
   "source": [
    "# 4. CODE FOR COMPARISON OF BASE MODEL OF LARGE MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShwOwlpquGEN"
   },
   "source": [
    "## 1. Large Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pPzQZrAUuGEN",
    "outputId": "32ae224d-a8be-40e5-a81b-a934fb01e716"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "============================================================\n",
      "STARTING LARGE MODEL EXPERIMENT (XLM-ROBERTA-LARGE)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EXPERIMENT 2: XLM-ROBERTA-LARGE COMPARISON\n",
    "# ============================================================================\n",
    "import gc\n",
    "\n",
    "# 1. CLEANUP to free VRAM from previous model\n",
    "try:\n",
    "    del model\n",
    "    del optimizer\n",
    "    del scheduler\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STARTING LARGE MODEL EXPERIMENT (XLM-ROBERTA-LARGE)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 2. CONFIG FOR LARGE MODEL (Reduced Batch Size to avoid OOM)\n",
    "LARGE_BATCH_SIZE = 4       # Reduced from 16 to 4 to fit in memory\n",
    "LARGE_GRAD_ACCUM = 8       # Increased to maintain effective batch size of 32\n",
    "LARGE_EPOCHS = 6           # Reduced slightly as large models learn faster\n",
    "LARGE_LR = 1e-5            # Lower learning rate for stability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iGlWIEexuGEN"
   },
   "source": [
    "## 2. Large Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195,
     "referenced_widgets": [
      "e13850e1d9ab4dd8ab18557cc7a0cbdf",
      "343c96fbe0954b8a8e40aa1029edb75d",
      "3cc2262c74eb4d6bad0d43535d40401f",
      "d0ef6dd8149b40a0b53bcd8689120ede",
      "46eaf97357774461a2cea7c342e5b7d5",
      "8032bad57c784f43a25f5fb976bad361",
      "2b32d1bf73434523a2da3bb1df07f804",
      "9529079111164162ae8c2159d20ab25d",
      "e398f882ddf44eba9141f5c8544b052b",
      "296d934c47b54bb4863d568e80397184",
      "05bd0b3b68c24ac0b66f102f42606d11",
      "287c17b8bfc64d0db568894db3452ecb",
      "ae54408533b24202b5ebcfe6e50dd638",
      "79ce3e582a174eeb99ef8d1439662e96",
      "87887a9da2774233bdb82c071f0b600b",
      "85647e9ecbe24a4cbd7965e5b43dd701",
      "7ab6303fce314c10a4c6c28e8e640289",
      "0ab8f61c70e74c7eae326fc5c79e671f",
      "674568f328d6432e9bf8fd95dbd38c22",
      "fad55197f68445949ca3d12063a032dc",
      "95e4268308fd4161ba7ed3cf36a2be4c",
      "9c70c946a0ca49659da32d51f156b6d8",
      "d546e9f145154de99124946cf815d20f",
      "593dc7da157a4f4da029d6ce19e6ce04",
      "735bedb72b1b45f5b89f9c862d8f5e55",
      "a3fb7bf6528745b5b71129dcf25b7a05",
      "3b4df75288444e5c8ea3ca23a347dae3",
      "da9583c365084fb8a09ad2b0093ba41b",
      "85c704c4e7d241c0b3a5490e3840914d",
      "e3a66920c0ee49dbb2bccb93c873f34e",
      "94db3da1e72546e280df1c1a7617faf9",
      "b3b7558fb9594e1d937beff756fc0232",
      "b1f61ef0f5e7414ea129c30f449ce923",
      "3942efad188a45759230d13a16054fe8",
      "3b17c425c80b40f5a88b863025cbdc04",
      "af4e6b75bda2488ebe1174d9f772d683",
      "f65f3b158529483ab51b9af0312f8fc9",
      "2fa68bad49bd4b2492d2f68eec465e2b",
      "49d84d0fa3da4c508bf5055536400cf0",
      "9e513da559ac464989f2967d55cef73f",
      "073aaf50cfb944f2937d954c58ac1133",
      "02606a137d8e460db766426603ee9a4b",
      "93b825f0495e41ccb734a199c175c3c4",
      "f72e9dbda97b46c0b2b650cff84bd133",
      "9ad646224c244d57b3671a09dd32d1d1",
      "3a0c638bfd7b49a0b91c8da37b0a5f34",
      "4d1add676e1240928b2c96580116812f",
      "3e65bb2ba08a42d59fc75df136e276fa",
      "5c1d5364138041ce8d3d9aaadaa4b17e",
      "ed1f464d0d2e42878ecbf53e106c8638",
      "efef5014ffe54481b270f29effa7bf83",
      "68a928b244be4ff79701b7be8f441c50",
      "e11334587f4941a895c86cdad90ad29e",
      "2c3b3c3b5efa4c57bd3e7b90c9eda818",
      "8f5516aa1c674662b7b958d513b032ff"
     ]
    },
    "id": "t6vSJrz6uGEN",
    "outputId": "aafaedb4-4c65-49c2-b938-af6af12ba882"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading xlm-roberta-large... (This may take a minute)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e13850e1d9ab4dd8ab18557cc7a0cbdf"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "287c17b8bfc64d0db568894db3452ecb"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d546e9f145154de99124946cf815d20f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3942efad188a45759230d13a16054fe8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9ad646224c244d57b3671a09dd32d1d1"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "# 3. DEFINE LARGE MODEL ARCHITECTURE\n",
    "class ContrastiveXLMR_Large(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super().__init__()\n",
    "        # Load the LARGE version\n",
    "        self.roberta = XLMRobertaModel.from_pretrained('xlm-roberta-large')\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "        # Projection Head (Input size is now 1024 for Large)\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 128)\n",
    "        )\n",
    "\n",
    "        # Classification Head (Input size 1024)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1024, 2048), nn.LayerNorm(2048), nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(2048, num_labels)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Enable gradient checkpointing to save memory\n",
    "        if self.training:\n",
    "            self.roberta.gradient_checkpointing_enable()\n",
    "\n",
    "        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "        proj_features = self.projection(pooled_output)\n",
    "        logits = self.classifier(self.dropout(pooled_output))\n",
    "\n",
    "        return logits, proj_features\n",
    "\n",
    "# 4. INITIALIZE\n",
    "print(\"Loading xlm-roberta-large... (This may take a minute)\")\n",
    "tokenizer_large = XLMRobertaTokenizer.from_pretrained('xlm-roberta-large')\n",
    "model_large = ContrastiveXLMR_Large(NUM_LABELS).to(device)\n",
    "\n",
    "# Re-create DataLoaders with smaller batch size for Large model\n",
    "train_loader_large = DataLoader(\n",
    "    PolarDataset(train_df['text_clean'].values, train_labels, tokenizer_large),\n",
    "    batch_size=LARGE_BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "dev_loader_large = DataLoader(\n",
    "    PolarDataset(dev_df['text_clean'].values, dev_labels, tokenizer_large),\n",
    "    batch_size=LARGE_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "optimizer_large = AdamW(model_large.parameters(), lr=LARGE_LR, weight_decay=0.01)\n",
    "total_steps = len(train_loader_large) * LARGE_EPOCHS // LARGE_GRAD_ACCUM\n",
    "scheduler_large = get_cosine_schedule_with_warmup(optimizer_large, int(0.1*total_steps), total_steps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ize-Mcz5uGEN"
   },
   "source": [
    "## 3. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245,
     "referenced_widgets": [
      "90f542edac294119b58be62510e7c06b",
      "1b14d1e6dcfa4e26808d53c3e60982e5",
      "510e936289564cd684eff08b401dc017",
      "28adcb1f77e04126aea166e2c12c41bb",
      "2b18826c28d24f28b6f60a74b305bd53",
      "209d10a0d3a145feb42fecf586040733",
      "bc6922ebdfb244c588174a263fc2e92a",
      "f175ee7cd31f452489572e774d481b78",
      "72feb7080cf84468816428312bf891fe",
      "2fd482ffb17642d1a5a0c3bb23e3f118",
      "f9d5f6da183e4f69a5e9a0d210191832",
      "319e7a088d54417b9755e67d3f6386d0",
      "0427b23f0b96499c98b7351dc250e5a3",
      "15dc6ff7de0b4a04bb6d2d64c79409d6",
      "f8d633b6386c4053bce27e885e362f0e",
      "08639847e27741cdbec66f2912d2de7a",
      "fac1a404ed544855bd2875cc8c68aaca",
      "2319f7155dd846bf95119aa3c52bca1e",
      "bed6d034bc6e4db59a3e8b28d0a1b00b",
      "0bd3b05636ce4d5db789e2ead8567e42",
      "28da8c72b4fe4433a8d1525c0b666c8c",
      "d9a255af74d54bfbbb5c4fefc30b8b2b",
      "eb36f50d03934e5faae06dac4c4d303a",
      "439156c1d61b4f99aca50e15591d7564",
      "b81fc8baea2646eabde58d275c66d309",
      "6c9ee62f11d94af99283947eda118ea0",
      "94704e5965024dbbb7852b0ce9d3603d",
      "6fd0dd0a8b3545ddb69a60654ee7e637",
      "6b0b48957b76497aa29d94d39028e4f7",
      "85bf34b2b9034949ad5098a8d410c5a3",
      "5c9e67798243401bbe83c494a86918bc",
      "71617059fbd94e0b9c0d02703d51cb4c",
      "14071b0cace548be80f5a1e185aac487",
      "121dd2127c55439e9f5f62794d88730e",
      "a7f3a83a071546aab7b42b0f22257ef7",
      "bd467a717d644c0f91e61e2a2239ce14",
      "b2e1616dda0642a5b7a125fff1efb8e3",
      "d0af003846134b18bffea3447764bc43",
      "890939af129b4f10b0332cd072bf00e0",
      "f402eb25ea1542a382f1a87e8edcdb1d",
      "a2bf4328d5704b24b4c5ae36f6be4e88",
      "5a041adb9b6742049eabece8ea97dec3",
      "56f4f67168e04e68bd1e0bdaa2a45bad",
      "eb206f39545e4819b5998e51620b19f1",
      "16d10e4c96f74bedb8c5132271b7dba1",
      "43b066de110c43fea2975c3abd70eb9b",
      "c4aeafe994104cdcbf1d23051f345e2c",
      "f6c5297351cc4c16b555758e17b859e5",
      "d48d170907cc477599095e76064b7e98",
      "18d62e0e38654ca4899fc434c897fac7",
      "586978b137714500b2cd2d2dc08c2f09",
      "e45690f5077a4adba692c7f8be94641b",
      "acf89ac9fc5a49e7b2b59788ffed7123",
      "958aa8a4538a45dbb1bc29a98a6e44ed",
      "786adb01ddcd4846aab864b831856976",
      "8335c3cf3917431cbeec9dc0dc30bb92",
      "41a932092b15413ab09ebed97e8eb465",
      "275ec0a2d4e24a718a37849cd3852fda",
      "ae8ba949ee234fb8bd9854779854de01",
      "86ab4064c9774a5e809fd4fccdccb10c",
      "6292aacab45a423eb35458e797b4aafc",
      "4f0974ff807b4d4e9a6df3f03be3a8fe",
      "d9de7744f6db4559b6a43fc992e45d5e",
      "5ed7d7c1b76d4d07809a0bb1ad45be15",
      "9c2a1ce7870248aabf167ed8edd38698",
      "ad362807af274494a29e7d832f72e3e0"
     ]
    },
    "id": "CWMwthMguGEO",
    "outputId": "721595d4-6279-499e-fc81-d3243ba096ff"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Starting Training (Effective Batch Size: 32)...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch 1:   0%|          | 0/5998 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "90f542edac294119b58be62510e7c06b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch 2:   0%|          | 0/5998 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "319e7a088d54417b9755e67d3f6386d0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch 3:   0%|          | 0/5998 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eb36f50d03934e5faae06dac4c4d303a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch 4:   0%|          | 0/5998 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "121dd2127c55439e9f5f62794d88730e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch 5:   0%|          | 0/5998 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "16d10e4c96f74bedb8c5132271b7dba1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch 6:   0%|          | 0/5998 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8335c3cf3917431cbeec9dc0dc30bb92"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "\n",
    "# 5. TRAINING LOOP (LARGE)\n",
    "best_f1_large = 0\n",
    "print(f\"\\nStarting Training (Effective Batch Size: {LARGE_BATCH_SIZE*LARGE_GRAD_ACCUM})...\")\n",
    "\n",
    "for epoch in range(LARGE_EPOCHS):\n",
    "    model_large.train()\n",
    "    loss_sum = 0\n",
    "    optimizer_large.zero_grad()\n",
    "\n",
    "    for step, batch in enumerate(tqdm(train_loader_large, desc=f\"Epoch {epoch+1}\")):\n",
    "        ids = batch['input_ids'].to(device)\n",
    "        mask = batch['attention_mask'].to(device)\n",
    "        lbls = batch['labels'].to(device)\n",
    "\n",
    "        logits, feats = model_large(ids, mask)\n",
    "\n",
    "        # Loss Calculation\n",
    "        loss = criterion_cls(logits, lbls) + (0.5 * criterion_scl(feats, lbls).mean())\n",
    "        loss = loss / LARGE_GRAD_ACCUM\n",
    "        loss.backward()\n",
    "\n",
    "        if (step + 1) % LARGE_GRAD_ACCUM == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model_large.parameters(), 1.0)\n",
    "            optimizer_large.step()\n",
    "            scheduler_large.step()\n",
    "            optimizer_large.zero_grad()\n",
    "\n",
    "        loss_sum += loss.item() * LARGE_GRAD_ACCUM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjabDKPXuGEO"
   },
   "source": [
    "## 4. Evaluation Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887,
     "referenced_widgets": [
      "7ceb578f27c74afe832681db76156157",
      "dd5ce830acfd4f86bb0aadf47a62aa95",
      "336e6bcf8d524f98ab1977cc775fcb26",
      "e85ddb77665445b4901df9e5122652ae",
      "29937c2a52e74c6cb574c226310c7988",
      "cd94d76c861b4d81bb91b8bcb8ea587d",
      "ced3d1a622b14c8ea851b077281a7621",
      "74c046c9f6654ca7a78a432eccb3826b",
      "115cc10c74174676b27132abee7b5a0a",
      "ba03a163573c4b83b9b6232feaf503f4",
      "71d130628d314db5860dfd4abff3a097",
      "2c04c957b7434b7c9d73fd23a898e986",
      "980724a629f445f690e4e896d36cf844",
      "a266319e80b64bc48fe868860aafc6a0",
      "95ff6c917bfd49769705e8662f80e0cb",
      "6a940474cae9451ea5f9c48f2e3fa0b1",
      "560a0436187f4ef3817a02b2c6cfd4de",
      "c9aa8ac2ee4c4734865e0cfc25a1e801",
      "d5f43392cab5452fb24281f12ddd685e",
      "7d098a8eed384e08ab37522e9a1a69d3",
      "7dd4fa20c54d4c65b151ee5718b0c519",
      "a18a19ecf132457d8f8f824f730af254",
      "68f4f7aa5abd44f083dffb69a86ef143",
      "54f6a4b341cc45a895e25ed1f9709f0d",
      "5b1a6ff0663845a5b6c4e2c5ce6ae399",
      "4f34c64364fb486490a75ae6c637b75a",
      "d7947b13b1d64fe99399aca7477eeaee",
      "a82eb77ff0fc43659784a9a2c96e6b7e",
      "558045f3513d4927990b15c41540b5ab",
      "554867ec1e734d2cbfb83d304eff8ed3",
      "a27d5d5d46874abf904a8f3eead9c3b0",
      "2a367b503f8d494b9702f3dc5296edb5",
      "6af6f5561d8a49b7bd549aa21b2440d5",
      "9b1906907c6c4a638ed67f345e65d19e",
      "26dcc7e2d06845059c8235d74567a290",
      "5e64d7954456408faa366131f73fb669",
      "a674fd12e9fc49aa89f6c7688a0bc71e",
      "07a2867797144704b2cb9f8ba4d92850",
      "a14390b37782417795c2c2d0d4675fc1",
      "43bb56082219486c8c2340f632053219",
      "e1cee3f0df1b4109aa07362c1712d457",
      "0703c335b3d14682a20753cc06517db4",
      "13619ae8386d4f0da529e64896fef364",
      "83d2998e7b8e4b9e85a1c3e18fbe9622",
      "5f1d3579841b41a79d25b6525aa1e3f6",
      "7457a39d23bb4b42a732b7d909d793a6",
      "1ee31f635f3f4891bab83f3bd6f5e0be",
      "05830b7e9dd94a508c1e00c4b390c640",
      "cba170bb3b7749e9b7ec49fa556db229",
      "5ca443d07fdc4c7f9e90853848ba12f6",
      "e24927aecc7a471ab18fec5e299ceebb",
      "e337f52ecbb7421589168832b5bc19a3",
      "d9fa34f9684c4b798a19d390ae3a2545",
      "f0cf529e098041308f70a917ab2b0127",
      "5953309f92664f0e8e40eb67a0e60b75",
      "fab9bea6c8d149b280acca4767dae456",
      "5d8ac5bce4424a728121c558847ead22",
      "a17307ead02144c0a75ddef0c8eff192",
      "7727fd410b174ed3918d6b2e5a9ec371",
      "ce7c4dfdb5d3437d9f498bb4fab980ca",
      "999f0a42d2334af3b48219a9e6671339",
      "4d8323417d944eef8b1e64f3371df32b",
      "85e73b8028d7417cb52a81ff3ff16c05",
      "4a31a27d360940b8aeae5bcb2f1fefe2",
      "d03f5f71f052437fa31c66cbd2773931",
      "f3e3ffdf96554540b78241f0e6cb469c",
      "890201ba4b02470891c41f4a0b89d0df",
      "4ec2c5ec923d44be897cabe08fb25a01",
      "98bd377c0fbb444f9c310ee13480a830",
      "7d239364c3a2499bb962f9787e79b3fe",
      "12743d9ccc6b41db96caba1813fc90f1",
      "4c302370fe4d431083cbb619051fbf3f",
      "6c9bd66509ba468896360366ebf5a0ca",
      "5011d0e869574bb9995500125c420893",
      "9953154047904170976bcd4f57004538",
      "c0932a73a03d4809a5db8644303919cd",
      "fc0930dd4b9b4635bfc21517ed101785",
      "18f7ec18c1b740589326bd17f8c85db6",
      "f55210b71ee441138cb1ad41dcdf9e2f",
      "057e6cc8ac2a4e8f8a4a2e35af078db7",
      "2d6a5a35be0b4e93ae53f31bb4335419",
      "2b1412ffef414a928a2fc3b180593d00",
      "7cf5d15641f5489dad1c73a038f1933c",
      "66b1aaf9d6ef41dfbea82e41eaf5b0bd",
      "7a7876e7df07418fbb44acdac7bcf60b",
      "51c54ce8b12044ada545c8374eead29b",
      "f02df5fcad9b4b088811559546b5ebc9",
      "9928810e6a3e476cb121558c64523aad",
      "bc81da77e92241d297172ab856f3f2d4",
      "79c70f07ec694dcda302f0ef52dbb751",
      "10071c2900ba4e76b7f9c4a4af6682a8",
      "ac4dc2cc40dc4789a5fd6f1b08bfc833",
      "72fa232985874a56a162099f0a9819f3",
      "3591172e9d244a5585cc89e6edc11f84",
      "bc6e46bb7d5a42a99d9e25a293ff61f6",
      "dd98a54eb12a4368b2bf62e4733d3303",
      "a87a1f0305c84f23807af34db13e0c6c",
      "737e55ba3c5e4d66b2ef4ae3737b1c33",
      "d719384572b14111b4939f20cd7fa880",
      "24dbac9fe2eb4898bcb9ad08d903a878",
      "08269ffdda314854a350a911b7d3cbfd",
      "aeaeb665cae44d1a98155e4d0a1908ab",
      "0f6e54d420f54c639988f77de754037a",
      "786dde5f8589478ca4669173b63b703b",
      "3cdb69f324bc4610afdb7c11bd753e9a",
      "4496702a98114885b1be8f2ace090c6c",
      "866bcbfc25894f388311caf23af2fcfa",
      "3017947dba5346418f563c2047bd4b78",
      "8b66ebb70ae6428491f062f65b513b30",
      "064edadaee3446b686e65a674cdcbc32",
      "6deb05f1dff747a69ca76d169b03a8db",
      "f0dd838208ed4ac3aa49885e35dcdedd",
      "1faf7a98eb314697871d212775b0a519",
      "deebadca31da4c4e995a7070ac81109b",
      "3ce455f4aa794dd2b074a4e0f41518a9",
      "177e413e2a6a436bad6f83a450f779a8",
      "d7323e77fabf41e3b8361bca2dc9a209",
      "0bf46bc235c24d0c860ed51e44ab0ec1",
      "2a559d68a6424fb9bcc998698de87b2e",
      "8fa1f7ec11694302869eda0ce4d47811",
      "e1ecdb787b604c099d4a7c130839db09"
     ]
    },
    "id": "7cftFmoyZ7no",
    "outputId": "d095499c-8e82-481a-d128-9bb17d50e342"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STARTING LARGE MODEL EXPERIMENT (XLM-ROBERTA-LARGE)\n",
      "============================================================\n",
      "Loading xlm-roberta-large... (This may take a minute)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ceb578f27c74afe832681db76156157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c04c957b7434b7c9d73fd23a898e986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f4f7aa5abd44f083dffb69a86ef143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1906907c6c4a638ed67f345e65d19e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f1d3579841b41a79d25b6525aa1e3f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Training (Effective Batch Size: 32)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab9bea6c8d149b280acca4767dae456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/5998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 0.2943 | Dev Macro F1: 0.5506\n",
      "\u2713 Saved Best Large Model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "890201ba4b02470891c41f4a0b89d0df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/5998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Loss: 0.2141 | Dev Macro F1: 0.6442\n",
      "\u2713 Saved Best Large Model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f7ec18c1b740589326bd17f8c85db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/5998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Loss: 0.1896 | Dev Macro F1: 0.6516\n",
      "\u2713 Saved Best Large Model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc81da77e92241d297172ab856f3f2d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/5998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Loss: 0.1729 | Dev Macro F1: 0.6661\n",
      "\u2713 Saved Best Large Model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24dbac9fe2eb4898bcb9ad08d903a878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/5998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Loss: 0.1610 | Dev Macro F1: 0.6667\n",
      "\u2713 Saved Best Large Model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6deb05f1dff747a69ca76d169b03a8db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/5998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Loss: 0.1552 | Dev Macro F1: 0.6675\n",
      "\u2713 Saved Best Large Model\n",
      "\n",
      "============================================================\n",
      "FINAL EXPERIMENTAL RESULTS (BASE VS LARGE)\n",
      "============================================================\n",
      "Model                | Macro F1       \n",
      "----------------------------------------\n",
      "XLM-R Base           | 0.6510\n",
      "XLM-R Large          | 0.6675\n",
      "----------------------------------------\n",
      "Improvement: 2.53%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "    # Evaluation\n",
    "    model_large.eval()\n",
    "    all_probs, all_lbls = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in dev_loader_large:\n",
    "            ids = batch['input_ids'].to(device)\n",
    "            mask = batch['attention_mask'].to(device)\n",
    "            logits, _ = model_large(ids, mask)\n",
    "            all_probs.append(torch.sigmoid(logits).cpu().numpy())\n",
    "            all_lbls.append(batch['labels'].cpu().numpy())\n",
    "\n",
    "    if len(all_probs) > 0:\n",
    "        y_probs = np.vstack(all_probs)\n",
    "        y_true = np.vstack(all_lbls)\n",
    "\n",
    "        # Optimize Thresholds\n",
    "        current_thresholds, _ = optimize_thresholds(y_true, y_probs)\n",
    "        y_pred = np.zeros_like(y_probs)\n",
    "        for i, t in enumerate(current_thresholds):\n",
    "            y_pred[:, i] = (y_probs[:, i] > t).astype(int)\n",
    "\n",
    "        macro_f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "        print(f\"Epoch {epoch+1} | Loss: {loss_sum/len(train_loader_large):.4f} | Dev Macro F1: {macro_f1:.4f}\")\n",
    "\n",
    "        if macro_f1 > best_f1_large:\n",
    "            best_f1_large = macro_f1\n",
    "            torch.save(model_large.state_dict(), 'best_model_large.pt')\n",
    "            print(\"\u2713 Saved Best Large Model\")\n",
    "\n",
    "# 6. FINAL COMPARISON TABLE\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL EXPERIMENTAL RESULTS (BASE VS LARGE)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Model':<20} | {'Macro F1':<15}\")\n",
    "print(\"-\" * 40)\n",
    "# Note: best_macro_f1 comes from the previous experiment (Base model)\n",
    "# If you didn't run the base model experiment in this session, replace with your recorded number.\n",
    "base_score = best_macro_f1 if 'best_macro_f1' in globals() else 0.0\n",
    "print(f\"{'XLM-R Base':<20} | {base_score:.4f}\")\n",
    "print(f\"{'XLM-R Large':<20} | {best_f1_large:.4f}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if base_score > 0:\n",
    "    improvement = ((best_f1_large - base_score) / base_score) * 100\n",
    "    print(f\"Improvement: {improvement:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}